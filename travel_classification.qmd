---
title: "Klasyfikacja ocen przejazdów"
subtitle: "Projekt z Eksploracji Danych"
author: "Igor Nowiński"
format: 
  html:
    code-fold: true
    code-tools: true
    code-summary: "Pokaż kod"
    code-overflow: wrap
    code-copy: true
    smooth-scroll: true
    highlight-style: arrow
    code-block-bg: true
    code-block-border-left: "#31BAE9"
    toc: true
    toc-title: "Spis treści"
language: 'polski.yml'
editor: source
echo: true
warning: false
message: false
self-contained: true
embed-resources: true
editor_options: 
  chunk_output_type: console
---

# Cel badania

Celem badania jest zbudowanie optymalnego modelu klasyfikacyjnego, którego zadaniem będzie klasyfikacja oceny końcowej. Dzięki temu będziemy mogli określić czy dany przejazd możemy uznać za wzorowy, dobry czy zły.


# Opis zbioru danych

Zbiór danych został zebrany na podstawie aplikacji Go!Track. Jest on dostępny na stronie [Uniwersytetu Kalifornijskiego w Irvine](https://archive.ics.uci.edu/dataset/354/gps+trajectories). Aplikacja pełniła rolę nawigatora GPS oraz służyła do szukania przewoźników. Dostępna ona była w sklepie [Google Play](https://web.archive.org/web/20170719115511/https://play.google.com/store/apps/details?id=com.go.router). Zbiór danych posiada 163 obserwacje i składa się z 10 zmiennych.

![](zdjęcia/go!track.png){fig-align="center" width="70%"}

`id_android` - numer identyfikacyjny urządzenia z którego pochodzą dane

`speed` - średnia prędkość pojazdy w kilometrach na godzinę

`distance` - dystans przejechany, liczony w kilometrach

`time` - czas podróży, liczony w godzinach

`rating` - zmienna nominalna, która przyjmuje 3 wartości. Jest to ogólna ocena przejazdu przez pasażera 
1 - źle,
2 - w porządku,
3 - dobrze

`rating_bus` - zmienna nominalna, określa poziom zatłoczenia w pojeździe
1 - mało pasażerów, 
2 - pojazd nie jest przepełniony, 
3 - pojazd jest przepełniony

`rating_weather` - określa, jaka była pogoda podczas podróży
1 - deszczowo,
2 - słonecznie 

`car_or_bus` - czy pasażer podróżował samochodem, czy autobusem
1 - samochód,
2 - autobus 

`linha` - informacja na temat pojazdu

```{r wczytanie bibliotek i danych, echo=FALSE}
library(rio)
library(tidyverse)
library(gt)
library(dplyr)
library(naniar)
library(tidymodels)
library(themis)
library(doParallel)
library(bestNormalize)
library(styler)
set.seed(2024)
df <- as.data.frame(import("dane/go_track_tracks.csv"))
```

```{r przedstawienie danych wejściowych}
#| label: tbl-pokazanie
#| tbl-cap: Przykładowe wartości zmiennych w zbiorze danych
head(df) %>%
  mutate(
    speed = round(speed, 2),
    time = round(time, 2),
    distance = round(distance, 2)
  ) %>%
  gt()
```

```{r parallel, eval = FALSE, echo=FALSE}
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
```

```{r Załadowanie customowych motywów, echo=FALSE}
theme_dark <- function() {
  theme(
    panel.background = element_rect(fill = "#222222"),
    plot.background = element_rect(
      fill = "#222222",
      colour = "white"
    ),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    axis.text = element_text(colour = "white"),
    axis.title = element_text(colour = "white"),
    legend.title = element_blank(),
    legend.background = element_rect(fill = "gray")
  )
}
theme_light <- function() {
  theme(
    panel.background = element_rect(fill = "white"),
    plot.background = element_rect(fill = "white"),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.major.y = element_line(color = "black"),
    panel.grid.minor.y = element_line(color = "gray30"),
    axis.text = element_text(colour = "black"),
    axis.title = element_text(colour = "black"),
    legend.title = element_blank(),
    legend.background = element_rect(fill = "gray"),
    axis.title.x = element_text(size = 14, vjust = -0.9),
    axis.title.y = element_text(size = 14, angle = 90, vjust = 1.5)
  )
}
```

# Przygotowanie zbioru

Ponieważ zbiór danych zawiera identyfikatory, do przeprowadzenia analizy zdecydowałem się usunąć kolumny `id` i `id_android`. Dodatkowo usuwam również kolumnę `linha`, ponieważ jest typu *chr*. Zamieniam zmienne nominalne na typ *factor*.

```{r usunięcie id, id_android i linha, echo=FALSE}
df <- df %>% select(-c(1, 2, 10))
df$rating <- factor(df$rating)
df$car_or_bus <- factor(df$car_or_bus)
```

### Nadmiarowość zmiennych

Zmienną`speed` można obliczyć ze wzoru poniżej, dlatego usuwam ją ze zbioru.

$$
speed[\frac{Km}{h}] = \frac{distance[Km]}{time[h]}
$$

```{r usunięcie speed, echo=FALSE}
df <- df %>%
  select(-speed)
```

Niestety zmienne `rating_bus` i `rating_weather` posiadają wiele wartości 0, co oznaczają braki danych. Zmieniłem poziomy *factor* tak, aby zaczynały się od zera. 

```{r releveling i zamiana na factor, echo=FALSE}
df$rating_bus <- ifelse(df$rating_bus == 0, NA, df$rating_bus)
df$rating_bus <- ifelse(df$rating_bus == 1, 0, df$rating_bus)
df$rating_bus <- ifelse(df$rating_bus == 2, 1, df$rating_bus)
df$rating_bus <- ifelse(df$rating_bus == 3, 2, df$rating_bus)
df$rating_weather <- ifelse(df$rating_weather == 0, NA, df$rating_weather)
df$rating_weather <- ifelse(df$rating_weather == 1, 0, df$rating_weather)
df$rating_weather <- ifelse(df$rating_weather == 2, 1, df$rating_weather)
df$rating <- ifelse(df$rating == 1, 0, df$rating)
df$rating <- ifelse(df$rating == 2, 1, df$rating)
df$rating <- ifelse(df$rating == 3, 2, df$rating)
df$car_or_bus <- ifelse(df$car_or_bus == 1, 0, df$car_or_bus)
df$car_or_bus <- ifelse(df$car_or_bus == 2, 1, df$car_or_bus)
df$rating_bus <- factor(df$rating_bus)
df$rating_weather <- factor(df$rating_weather)
df$rating <- factor(df$rating)
df$car_or_bus <- factor(df$car_or_bus)
```

```{r na czysto}
#| label: tbl-poczyszczeniu
#| tbl-cap: Przykładowe wartości zmiennych w zbiorze danych po usunięciu kolumn id, id_android, linha i konwersji typu danych
head(df) %>%
  mutate(
    time = round(time, 2),
    distance = round(distance, 2)
  ) %>%
  gt()
```

Nowe wartości zmiennych nominalnych:

`rating_bus`
0 - mało pasażerów, 
1 - pojazd nie jest przepełniony, 
2 - pojazd jest przepełniony

`rating_weather`
0 - deszczowo,
1 - słonecznie 

`car_or_bus`
0 - samochód,
1 - autobus 


W @tbl-liczebnosc możemy zauważyć, że obserwacji w których pojazd był zatłoczony jest tylko 3. Zbiór nie jest zbalansowany, co może prowadzić do problemów przy uczeniu i sprawdzaniu modeli uczenia maszynowego.

```{r Przedstawienie liczebności zmiennych nominalnych}
#| layout-ncol: 3
#| label: tbl-liczebnosc
#| tbl-cap: Przedstawienie liczebności zmiennych nominalnych
#| tbl-subcap: ["rating_bus", "rating_weather", "rating"]

tabela_rating_bus <- as.data.frame(table(df$rating_bus))
colnames(tabela_rating_bus) <- c("Poziom", "Liczebność")
tabela_rating_bus %>% gt()

tabela_rating_weather <- as.data.frame(table(df$rating_weather))
colnames(tabela_rating_weather) <- c("Poziom", "Liczebność")
tabela_rating_weather %>% gt()

tabela_rating <- as.data.frame(table(df$rating))
colnames(tabela_rating) <- c("Poziom", "Liczebność")
tabela_rating %>% gt()
```

### Sprawdzenie braków danych

```{r Sprawdzenie braków danych}
#| label: tbl-sprawdzeniebrakow
#| tbl-cap: Sprawdzenie występowania wartości NA w zbiorze danych
braki <- as.data.frame(t(colSums(is.na(df))))
braki %>% gt()
```

Stanowi to `r  round(pct_miss(df$rating_weather),2)`% obserwacji. Jest to bardzo dużo i logika podpowiada, że powinienem usunąć te dwie zmienne. Zdecydowałem natomiast o przeprowadzeniu imputacji danych, w celu zachowania obserwacji innych zmiennych. Wyniki będą porównane później.

### Imputacja danych

Ze względu na dużą ilość braków danych, zdecydowałem się imputować zmienne `rating_bus` i `rating_weather`. Użyłem do tego metody *rf* z biblioteki `mice`.

```{r Imputacja, echo=FALSE}
library(mice)
imputation_rf <- mice(df,
  seed = 2024,
  printFlag = F,
  method = "rf",
  m = 5,
  maxit = 10
)
```

```{r Przedstawienie jak zmienne zostały imputowane}
#| layout-ncol: 2
#| label: tbl-imp
#| tbl-cap: Imputacja danych metodą rf
#| tbl-subcap: ["rating_bus", "rating_weather"]

head(imputation_rf$imp$rating_bus, 10) %>% gt()

head(imputation_rf$imp$rating_weather, 10) %>% gt()
```

```{r stworzenie pełnych zbiorów danych, echo=FALSE}
imputation_1 <- complete(imputation_rf, action = 1)
imputation_2 <- complete(imputation_rf, action = 2)
imputation_3 <- complete(imputation_rf, action = 3)
imputation_4 <- complete(imputation_rf, action = 4)
imputation_5 <- complete(imputation_rf, action = 5)
imputation_6 <- complete(imputation_rf, action = 6)
```


#### Porównanie imputowanych zbiorów

##### rating_bus

::: {.panel-tabset}

## imputacja 1

```{r bus1}
#| label: fig-bus1
#| fig-cap: Rozkład obserwacji w klasach zmiennej rating_bus przy uzyciu 1 zbioru
theme_set(theme_light())
ggplot() +
  geom_bar(
    data = df,
    aes(x = rating_bus, fill = "pierwotne"),
    alpha = 0.5
  ) +
  geom_bar(
    data = imputation_1,
    aes(x = rating_bus, fill = "imputowane"),
    alpha = 0.5
  ) +
  scale_fill_manual(
    values = c(
      "pierwotne" = "blue",
      "imputowane" = "red"
    ),
    name = "Legend"
  ) +
  labs(y = "Ilość")
```

## imputacja 2

```{r bus2}
#| label: fig-bus2
#| fig-cap: Rozkład obserwacji w klasach zmiennej rating_bus przy użyciu 2 zbioru
theme_set(theme_light())
ggplot() +
  geom_bar(
    data = df,
    aes(x = rating_bus, fill = "pierwotne"),
    alpha = 0.5
  ) +
  geom_bar(
    data = imputation_2,
    aes(x = rating_bus, fill = "imputowane"),
    alpha = 0.5
  ) +
  scale_fill_manual(
    values = c(
      "pierwotne" = "blue",
      "imputowane" = "red"
    ),
    name = "Legend"
  ) +
  labs(y = "Ilość")
```

## imputacja 3

```{r bus3}
#| label: fig-bus3
#| fig-cap: Rozkład obserwacji w klasach zmiennej rating_bus przy użyciu 3 zbioru
theme_set(theme_light())
ggplot() +
  geom_bar(
    data = df,
    aes(x = rating_bus, fill = "pierwotne"),
    alpha = 0.5
  ) +
  geom_bar(
    data = imputation_3,
    aes(x = rating_bus, fill = "imputowane"),
    alpha = 0.5
  ) +
  scale_fill_manual(
    values = c(
      "pierwotne" = "blue",
      "imputowane" = "red"
    ),
    name = "Legend"
  ) +
  labs(y = "Ilość")
```

## imputacja 4

```{r bus4}
#| label: fig-bus4
#| fig-cap: Rozkład obserwacji w klasach zmiennej rating_bus przy użyciu 4 zbioru
theme_set(theme_light())
ggplot() +
  geom_bar(
    data = df,
    aes(x = rating_bus, fill = "pierwotne"),
    alpha = 0.5
  ) +
  geom_bar(
    data = imputation_4,
    aes(x = rating_bus, fill = "imputowane"),
    alpha = 0.5
  ) +
  scale_fill_manual(
    values = c(
      "pierwotne" = "blue",
      "imputowane" = "red"
    ),
    name = "Legend"
  ) +
  labs(y = "Ilość")
```

## imputacja 5

```{r bus5}
#| label: fig-bus5
#| fig-cap: Rozkład obserwacji w klasach zmiennej rating_bus przy użyciu 5 zbioru
theme_set(theme_light())
ggplot() +
  geom_bar(
    data = df,
    aes(x = rating_bus, fill = "pierwotne"),
    alpha = 0.5
  ) +
  geom_bar(
    data = imputation_5,
    aes(x = rating_bus, fill = "imputowane"),
    alpha = 0.5
  ) +
  scale_fill_manual(
    values = c(
      "pierwotne" = "blue",
      "imputowane" = "red"
    ),
    name = "Legend"
  ) +
  labs(y = "Ilość")
```

:::

##### rating_weather

::: {.panel-tabset}

## imputacja 1

```{r weather1}
#| label: fig-weather1
#| fig-cap: Rozkład obserwacji w klasach zmiennej rating_weather przy użyciu 1 zbioru
ggplot() +
  geom_bar(
    data = df,
    aes(x = rating_weather, fill = "pierwotne"),
    alpha = 0.5
  ) +
  geom_bar(
    data = imputation_1,
    aes(x = rating_weather, fill = "imputowane"),
    alpha = 0.5
  ) +
  scale_fill_manual(
    values = c(
      "pierwotne" = "blue",
      "imputowane" = "red"
    ),
    name = "Legend"
  ) +
  labs(y = "Ilość")
```


## imputacja 2

```{r weather2}
#| label: fig-weather2
#| fig-cap: Rozkład obserwacji w klasach zmiennej rating_weather przy użyciu 2 zbioru
ggplot() +
  geom_bar(
    data = df,
    aes(x = rating_weather, fill = "pierwotne"),
    alpha = 0.5
  ) +
  geom_bar(
    data = imputation_2,
    aes(x = rating_weather, fill = "imputowane"),
    alpha = 0.5
  ) +
  scale_fill_manual(
    values = c(
      "pierwotne" = "blue",
      "imputowane" = "red"
    ),
    name = "Legend"
  ) +
  labs(y = "Ilość")
```

## imputacja 3

```{r weather3}
#| label: fig-weather3
#| fig-cap: Rozkład obserwacji w klasach zmiennej rating_weather przy użyciu 3 zbioru
ggplot() +
  geom_bar(
    data = df,
    aes(x = rating_weather, fill = "pierwotne"),
    alpha = 0.5
  ) +
  geom_bar(
    data = imputation_3,
    aes(x = rating_weather, fill = "imputowane"),
    alpha = 0.5
  ) +
  scale_fill_manual(
    values = c(
      "pierwotne" = "blue",
      "imputowane" = "red"
    ),
    name = "Legend"
  ) +
  labs(y = "Ilość")
```

## imputacja 4

```{r weather4}
#| label: fig-weather4
#| fig-cap: Rozkład obserwacji w klasach zmiennej rating_weather przy użyciu 4 zbioru
ggplot() +
  geom_bar(
    data = df,
    aes(x = rating_weather, fill = "pierwotne"),
    alpha = 0.5
  ) +
  geom_bar(
    data = imputation_4,
    aes(x = rating_weather, fill = "imputowane"),
    alpha = 0.5
  ) +
  scale_fill_manual(
    values = c(
      "pierwotne" = "blue",
      "imputowane" = "red"
    ),
    name = "Legend"
  ) +
  labs(y = "Ilość")
```

## imputacja 5

```{r weather5}
#| label: fig-weather5
#| fig-cap: Rozkład obserwacji w klasach zmiennej rating_weather przy użyciu 5 zbioru
ggplot() +
  geom_bar(
    data = df,
    aes(x = rating_weather, fill = "pierwotne"),
    alpha = 0.5
  ) +
  geom_bar(
    data = imputation_5,
    aes(x = rating_weather, fill = "imputowane"),
    alpha = 0.5
  ) +
  scale_fill_manual(
    values = c(
      "pierwotne" = "blue",
      "imputowane" = "red"
    ),
    name = "Legend"
  ) +
  labs(y = "Ilość")
```

:::

```{r zapisanie wariancji imputacji, echo=FALSE}
wariancje <- as.data.frame(imputation_rf$chainVar[, 10, ][c(4, 5), ])
colnames(wariancje) <- c(
  "Zbiór 1", "Zbiór 2", "Zbiór 3",
  "Zbiór 4", "Zbiór 5"
)
```

```{r wyświetlenie wyników imputacji}
#| label: tbl-wynikiimp
#| tbl-cap: Wariancja imputacji rating_bus i rating_weather
as.data.frame(t(wariancje)) %>%
  mutate(
    rating_bus = round(rating_bus, 2),
    rating_weather = round(rating_weather, 2)
  ) %>%
  gt(rownames_to_stub = T)
```

Na podstawie wyników zamieszczonych w @tbl-wynikiimp wybieram zbiór imputowany przez *rf* w wersji 3.

```{r wybranie zbioru do dalszej analizy, echo=FALSE}
imputation_completed <- imputation_3
```


# Wizualizacja zbioru danych

::: {.panel-tabset}

## distance

```{r histogram distance}
#| label: fig-czestoscdistance
#| fig-cap: Rozkład częstotliwości występowania wartości zmiennej distance
imputation_completed %>%
  ggplot(aes(distance)) +
  geom_histogram(bins = 50) +
  scale_x_continuous(breaks = c(1, 2, 3, 4, 5, 10, 20, 30, 40, 50)) +
  scale_y_continuous(breaks = c(10, 20, 30, 40, 50)) +
  labs(
    x = "distance",
    y = "Częstość"
  )
```

Średni pokonany dystans wynosi `r round(mean(imputation_completed$distance),2)` Km, natomiast mediana `r round(median(imputation_completed$distance),2)` Km.

## time

```{r histogram time}
#| label: fig-czestoscdtime
#| fig-cap: Rozkład częstotliwości występowania wartości zmiennej distance
imputation_completed %>%
  ggplot(aes(time)) +
  geom_histogram(bins = 50) +
  scale_x_continuous(breaks = c(0.1, 0.2, 0.3, 0.4, 0.5, 1, 1.5, 2)) +
  scale_y_continuous(breaks = c(5, 10, 15, 20, 25, 30)) +
  labs(
    x = "time",
    y = "Częstość"
  )
```

Średnia czasu przejazdu wynosi `r round(mean(imputation_completed$time),2)` h, natomiast mediana `r round(median(imputation_completed$time),2)` h.

:::

```{r korelacja pomiędzy distance i time, echo=FALSE}
cor_dis_time <- cor(
  imputation_completed$distance,
  imputation_completed$time
)
```

Korelacja pomiędzy `distance` i `time` jest równa `r round(cor_dis_time,2)`. Jest to zrozumiałe, ponieważ w sytuacji długiego dystansu do pokonania również rośnie potrzebny czas.

## Sprawdzenie zależności pomiędzy zmiennymi nominalnymi

::: {.panel-tabset}

## car_or_bus vs rating_bus

```{r chisq_bus}
chisq.test(imputation_completed$car_or_bus, imputation_completed$rating_bus)
```

```{r fisher_bus}
fisher.test(imputation_completed$car_or_bus, imputation_completed$rating_bus)
```

Na podstawie testu $\chi^2$ i Fishera nie mam powodów do odrzucenia $H_0$ o braku zależności pomiędzy `car_or_bus` i `rating_bus`.

Oceny pojazdów nie są zależne od wyboru samochodu lub autokaru.

## car_or_bus vs rating_weather

```{r chisq_bus2}
chisq.test(imputation_completed$car_or_bus, imputation_completed$rating_weather)
```

```{r fisher_bus2}
fisher.test(imputation_completed$car_or_bus, imputation_completed$rating_weather)
```

Na podstawie testu $\chi^2$ i Fishera nie mam powodów do odrzucenia $H_0$ o braku zależności pomiędzy `car_or_bus` i `rating_weather`.

Wybór typu pojazdu nie jest zależny od pogody.

:::


# Budowa modeli klasyfikacyjnych

Zdecydowałem się na wybór dwóch lasów losowych z silnikiem `ranger`. Warto jest porównać czy imputacja danych była krokiem w dobrą stronę. 

Pierwszy model lasu losowego został nauczony na oryginalnym zbiorze danych, z usunięciem zmiennych `rating_bus` i `rating_weather`. Drugi, jak i reszta modeli, zostały nauczone na imputowanym zbiorze.

Następnymi modelami są:

-   Boosting(`XGBoost`)
-   SVM(`kernlab`)
-   Bagging(`C5.0`)
-   RDA(`klaR`)

Wybrałem je ze względu na ich popularność oraz szerokie zastosowania.

Ponieważ niektóre z tych modeli potrzebują dodatkowych spełnionych przekształceń danych, sugerowałem się tymi zamieszczonymi [tutaj](https://www.tmwr.org/pre-proc-table).

Do budowy modeli użyłem paczki `tidymodels` oraz kilku dodatków, m.in. `dials` i `themis`.

Podzieliłem zbiór na część treningową i testową. Dodatkowo zastosowałem upsampling, aby zbalansować zbiór treningowy, z nadzieją, że poprawi to jakość dopasowania.

Użyłem siatek regularnych do wybrania parametrów modeli, które oznaczyłem do tuningu. Celem było stworzenie około 100 propozycji i wybranie tej najbardziej optymalnej. 

Do walidacji dopasowania wybrałem walidację krzyżową 10-krotną z 5-cioma powtórzeniami.

Skupiłem się na metryce *balanced accuracy*, ponieważ zbiór nie ma zbalansowanych klas, co można zauważyć w macierzach konfuzji wyników poniżej.

```{r Podział oryginalnego zbioru, eval=FALSE}
#| code-summary: Podział oryginalnego zbioru danych
set.seed(2024)
split_df <- initial_split(df[, c(-4, -5)])
train_df <- training(split_df)
test_df <- testing(split_df)
```

```{r podział zbioru z imputacji, eval=FALSE}
#| code-summary: Podział imputowanego zbioru danych
set.seed(2024)
split <- initial_split(imputation_completed)
train <- training(split)
test <- testing(split)
```

### Deklaracje, uczenie oraz sprawdzenie modeli
::: {.panel-tabset}

## Las losowy z usunięciem zmiennych

```{r Las na surowych danych, eval=FALSE}
#| code-fold: show
set.seed(2024)
rec <- recipe(rating ~ ., data = train_df) %>%
  step_upsample(rating)
rf <- rand_forest(
  mode = "classification",
  mtry = tune(),
  min_n = tune(),
  trees = tune()
) %>%
  set_engine("ranger")

control_settings <- control_grid(save_pred = TRUE)
wflow <- workflow() %>%
  add_recipe(rec) %>%
  add_model(rf)

param <- extract_parameter_set_dials(wflow)

param <- param %>% update(mtry = mtry(c(1, 3)))

grid <- grid_regular(param, levels = 5)

metrics <- metric_set(bal_accuracy)

cv <- vfold_cv(train_df, v = 10, repeats = 5)

tuning <- tune_grid(
  object = wflow,
  grid = grid,
  resamples = cv,
  metrics = metrics,
  control = control_settings,
  param_info = param
)

best_models <- show_best(tuning, metric = "bal_accuracy")

final_wflow <- finalize_workflow(
  wflow,
  best_models[1, ]
)

wflow_fit <- fit(final_wflow, data = train_df)

pred_test <- predict(wflow_fit, test_df)

cm <- pred_test %>%
  bind_cols(test_df) %>%
  conf_mat(truth = rating, estimate = .pred_class)
```

```{r zapis cm surowego rf, eval=FALSE, echo=FALSE}
saveRDS(cm, "rds/cm.rds")
saveRDS(best_models, "rds/best_models.rds")
```

```{r wczytanie cm surowego rf, echo=FALSE}
cm <- readRDS("rds/cm.rds")
best_models_df <- readRDS("rds/best_models.rds")
```

```{r cm surowego rf, echo=FALSE}
sum_cm <- summary(cm)[c(1, 2, 3, 4, 9), ] %>% select(.metric, .estimate)
```

## Las losowy

```{r Las na zbiorze z imputacji, eval=FALSE}
#| code-fold: show
set.seed(2024)
rec <- recipe(rating ~ ., data = train) %>%
  step_upsample(rating)

rf <- rand_forest(
  mode = "classification",
  mtry = tune(),
  min_n = tune(),
  trees = tune()
) %>%
  set_engine("ranger")

control_settings <- control_grid(save_pred = TRUE)
wflow <- workflow() %>%
  add_recipe(rec) %>%
  add_model(rf)

param <- extract_parameter_set_dials(wflow)

param <- param %>% update(mtry = mtry(c(1, 5)))

grid <- grid_regular(param, levels = 5)

cv <- vfold_cv(train, v = 10, repeats = 5)

metrics <- metric_set(bal_accuracy)

tuning <- tune_grid(
  object = wflow,
  grid = grid,
  resamples = cv,
  metrics = metrics,
  control = control_settings,
  param_info = param
)

best_models <- show_best(tuning, metric = "bal_accuracy")

final_wflow <- finalize_workflow(
  wflow,
  best_models[1, ]
)

wflow_fit <- fit(final_wflow, data = train)

pred_test <- predict(wflow_fit, test)

cm_rf <- pred_test %>%
  bind_cols(test) %>%
  conf_mat(truth = rating, estimate = .pred_class)
```

```{r zapis cm rf z imputacją, eval=FALSE, echo=FALSE}
saveRDS(cm_rf, "rds/cm_rf.rds")
saveRDS(best_models, "rds/best_models_rf.rds")
```

```{r wczytanie cm rf z imputacją, echo=FALSE}
cm_rf <- readRDS("rds/cm_rf.rds")
best_models_rf <- readRDS("rds/best_models_rf.rds")
```

```{r cm rf z imputacją, echo=FALSE}
sum_cm_rf <- summary(cm_rf)[c(1, 2, 3, 4, 9), ] %>% select(.metric, .estimate)
```

## XGBoost

```{r boosting, eval=FALSE}
#| code-fold: show
set.seed(2024)
rec <- recipe(rating ~ ., data = train) %>%
  step_upsample(rating) %>%
  step_dummy(all_nominal_predictors())


boost <- boost_tree(
  mode = "classification",
  mtry = tune(),
  min_n = tune(),
  trees = tune(),
  learn_rate = tune(),
  loss_reduction = tune(),
  tree_depth = tune(),
  sample_size = tune()
) %>%
  set_engine("xgboost")

control_settings <- control_grid(save_pred = TRUE)
wflow <- workflow() %>%
  add_recipe(rec) %>%
  add_model(boost)

param <- extract_parameter_set_dials(wflow)

param <- param %>% update(mtry = mtry(c(1, 5)))

grid <- grid_regular(param, levels = 2)

cv <- vfold_cv(train, v = 10, repeats = 5)

metrics <- metric_set(bal_accuracy)
tuning <- tune_grid(
  object = wflow,
  grid = grid,
  resamples = cv,
  metrics = metrics,
  control = control_settings,
  param_info = param
)

best_models <- show_best(tuning, metric = "bal_accuracy")

final_wflow <- finalize_workflow(
  wflow,
  best_models[1, ]
)

wflow_fit <- fit(final_wflow, data = train)

pred_test <- predict(wflow_fit, test)

cm_boost <- pred_test %>%
  bind_cols(test) %>%
  conf_mat(truth = rating, estimate = .pred_class)
```

```{r zapis cm boosting, eval=FALSE, echo=FALSE}
saveRDS(cm_boost, "rds/cm_boost.rds")
saveRDS(best_models, "rds/best_models_boost.rds")
```

```{r wczytanie cm boosting, echo=FALSE}
cm_boost <- readRDS("rds/cm_boost.rds")
best_models_boost <- readRDS("rds/best_models_boost.rds")
```

```{r cm boosting, echo=FALSE}
sum_cm_boost <- summary(cm_boost)[c(1, 2, 3, 4, 9), ] %>% select(.metric, .estimate)
```

## SVM

```{r svm, eval=FALSE}
#| code-fold: show
set.seed(2024)
rec <- recipe(rating ~ ., data = train) %>%
  step_upsample(rating) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_best_normalize(all_numeric_predictors()) %>%
  step_corr(all_numeric_predictors()) %>%
  step_best_normalize(all_numeric_predictors()) %>%
  step_YeoJohnson(all_numeric_predictors())

svm <- svm_rbf(cost = tune(), rbf_sigma = tune()) %>%
  set_engine("kernlab") %>%
  set_mode("classification")

control_settings <- control_grid(save_pred = TRUE)
wflow <- workflow() %>%
  add_recipe(rec) %>%
  add_model(svm)

param <- extract_parameter_set_dials(wflow)

grid <- grid_regular(param, levels = 10)

cv <- vfold_cv(train, v = 10, repeats = 5)

metrics <- metric_set(bal_accuracy)

tuning <- tune_grid(
  object = wflow,
  grid = grid,
  resamples = cv,
  metrics = metrics,
  control = control_settings,
  param_info = param
)

best_models <- show_best(tuning, metric = "bal_accuracy")

final_wflow <- finalize_workflow(
  wflow,
  best_models[1, ]
)

wflow_fit <- fit(final_wflow, data = train)

pred_test <- predict(wflow_fit, test)

cm_svm <- pred_test %>%
  bind_cols(test) %>%
  conf_mat(truth = rating, estimate = .pred_class)
```

```{r zapis cm svm, eval=FALSE, echo=FALSE}
saveRDS(cm_svm, "rds/cm_svm.rds")
saveRDS(best_models, "rds/best_models_svm.rds")
```

```{r wczytanie cm svm, echo=FALSE}
cm_svm <- readRDS("rds/cm_svm.rds")
best_models_svm <- readRDS("rds/best_models_svm.rds")
```

```{r cm svm, echo=FALSE}
sum_cm_svm <- summary(cm_svm)[c(1, 2, 3, 4, 9), ] %>% select(.metric, .estimate)
```

## Bagging

```{r bag, eval=FALSE}
#| code-fold: show
rec <- recipe(rating ~ ., data = train) %>%
  step_upsample(rating)


bag <- bag_tree(
  mode = "classification",
  min_n = tune()
) %>%
  set_engine("C5.0")

control_settings <- control_grid(save_pred = TRUE)
wflow <- workflow() %>%
  add_recipe(rec) %>%
  add_model(bag)

param <- extract_parameter_set_dials(wflow)

grid <- grid_regular(param, levels = 10)

cv <- vfold_cv(train, v = 10, repeats = 5)

metrics <- metric_set(bal_accuracy)
tuning <- tune_grid(
  object = wflow,
  grid = grid,
  resamples = cv,
  metrics = metrics,
  control = control_settings,
  param_info = param
)

best_models_bag <- show_best(tuning, metric = "bal_accuracy")

final_wflow <- finalize_workflow(
  wflow,
  best_models_bag[1, ]
)

wflow_fit <- fit(final_wflow, data = train)

pred_test <- predict(wflow_fit, test)

cm_bag <- pred_test %>%
  bind_cols(test) %>%
  conf_mat(truth = rating, estimate = .pred_class)
```

```{r zapis bag, eval=FALSE, echo=FALSE}
saveRDS(best_models_bag, "rds/best_models_bag.rds")
saveRDS(cm_bag, "rds/cm_bag.rds")
```

```{r wczytanie bag, echo=FALSE}
best_models_bag <- readRDS("rds/best_models_bag.rds")
cm_bag <- readRDS("rds/cm_bag.rds")
```

```{r, echo=FALSE}
sum_cm_bag <- summary(cm_bag)[c(1, 2, 3, 4, 9), ] %>% select(.metric, .estimate)
```


## RDA

```{r rda, eval=FALSE}
#| code-fold: show
rec <- recipe(rating ~ ., data = train) %>%
  step_upsample(rating) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_corr(all_numeric_predictors()) %>%
  step_nzv(all_numeric_predictors())


rda <- discrim_regularized(
  mode = "classification",
  frac_common_cov = tune(),
  frac_identity = tune()
) %>%
  set_engine("klaR")

control_settings <- control_grid(save_pred = TRUE)
wflow <- workflow() %>%
  add_recipe(rec) %>%
  add_model(rda)

param <- extract_parameter_set_dials(wflow)

grid <- grid_regular(param, levels = 10)

cv <- vfold_cv(train, v = 10, repeats = 5)

metrics <- metric_set(bal_accuracy)
tuning <- tune_grid(
  object = wflow,
  grid = grid,
  resamples = cv,
  metrics = metrics,
  control = control_settings,
  param_info = param
)

best_models_rda <- show_best(tuning, metric = "bal_accuracy")

final_wflow <- finalize_workflow(
  wflow,
  best_models_rda[1, ]
)

wflow_fit <- fit(final_wflow, data = train)

pred_test <- predict(wflow_fit, test)

cm_rda <- pred_test %>%
  bind_cols(test) %>%
  conf_mat(truth = rating, estimate = .pred_class)
```

```{r zapis rda, eval=FALSE, echo=FALSE}
saveRDS(best_models_rda, "rds/best_models_rda.rds")
saveRDS(cm_rda, "rds/cm_rda.rds")
```

```{r wczytanie rda, echo=FALSE}
best_models_rda <- readRDS("rds/best_models_rda.rds")
cm_rda <- readRDS("rds/cm_rda.rds")
```

```{r, echo=FALSE}
sum_cm_rda <- summary(cm_rda)[c(1, 2, 3, 4, 9), ] %>% select(.metric, .estimate)
```

:::

```{r zatrzymanie parallela, eval = FALSE, echo=FALSE}
stopCluster(cl)
```

# Podsumowanie i wnioski

Po dopasowaniu modeli do zbioru treningowego oraz sprawdzeniu ich na zbiorze testowym uzyskałem wyniki, które przedstawiłem poniżej.


### Metryki wyników na zbiorze treningowym

::: {.panel-tabset}

## Las losowy z usunięciem zmiennych

```{r}
#| label: tbl-wyniki_df
#| tbl-cap: Metryki modeli na zbiorze treningowym dla lasu losowego
best_models_df[, c(1:3, 6, 9)] %>%
  mutate(bal_accuracy = round(mean, 2)) %>%
  select(-mean) %>%
  gt()
```

## Las losowy

```{r}
#| label: tbl-wyniki_rf
#| tbl-cap: Metryki modeli na imputowanym zbiorze treningowym dla lasu losowego
best_models_rf[, c(1:3, 6, 9)] %>%
  mutate(bal_accuracy = round(mean, 2)) %>%
  select(-mean) %>%
  gt()
```

## XGBoost

```{r}
#| label: tbl-wyniki_boost
#| tbl-cap: Metryki modeli na zbiorze treningowym dla XGBoost
best_models_boost[, c(1:4, 7, 10, 13)] %>%
  mutate(bal_accuracy = round(mean, 2)) %>%
  select(-mean) %>%
  gt()
```

## SVM

```{r}
#| label: tbl-wyniki_svm
#| tbl-cap: Metryki modeli na zbiorze treningowym dla SVM
best_models_svm[, c(1:2, 5, 8)] %>%
  mutate(bal_accuracy = round(mean, 2)) %>%
  select(-mean) %>%
  summarise(
    cost = round(cost, 3), rbf_sigma = round(rbf_sigma, 3),
    .config, bal_accuracy
  ) %>%
  gt()
```

## Bagging

```{r}
#| label: tbl-wyniki_bag
#| tbl-cap: Metryki modeli na zbiorze treningowym dla Baggingu
best_models_bag[, c(1, 4, 7)] %>%
  mutate(bal_accuracy = round(mean, 2)) %>%
  select(-mean) %>%
  gt()
```

## RDA

```{r}
#| label: tbl-wyniki_rda
#| tbl-cap: Metryki modeli na zbiorze treningowym dla RDA
best_models_rda[, c(1, 2, 5, 8)] %>%
  mutate(bal_accuracy = round(mean, 2)) %>%
  select(-mean) %>%
  summarise(
    frac_common_cov = round(frac_common_cov, 3), frac_identity,
    .config, bal_accuracy
  ) %>%
  gt()
```

:::


### Metryki wyników na zbiorze testowym

```{r tabela wyników}
#| label: tbl-wyniki_test
#| tbl-cap: Metryki modeli na zbiorze testowym
wyniki_test <- cbind(
  sum_cm$.estimate, sum_cm_rf$.estimate,
  sum_cm_boost$.estimate, sum_cm_svm$.estimate,
  sum_cm_bag$.estimate, sum_cm_rda$.estimate
)
wyniki_test <- as.data.frame(matrix(sapply(wyniki_test, round, 2), byrow = F, ncol = 6))
colnames(wyniki_test) <- c(
  "rf", "imputowany rf",
  "XGBoost", "SVM", "Bagging", "RDA"
)
rownames(wyniki_test) <- sum_cm$.metric
wyniki_test %>% gt(rownames_to_stub = T)
```


### Macierze konfuzji

::: {.panel-tabset}

## Las losowy z usunięciem zmiennych

```{r cmplot}
#| label: fig-cm
#| fig-cap: Macierz konfuzji lasu losowego na oryginalnym zbiorze danych
DataFrame_cm <- as.data.frame(cm$table)
names(DataFrame_cm) <- c("Truth", "Prediction", "Częstotliwość")

# Visualization
ggplot(DataFrame_cm, aes(x = Truth, y = Prediction, fill = Częstotliwość)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Częstotliwość), vjust = 1.5, color = "white", size = 5) +
  scale_fill_gradient(low = "lightblue", high = "blue") +
  labs(
    title = "Macierz konfuzji", x = "Obserwowane",
    y = "Prawdziwe"
  ) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    plot.title = element_text(hjust = 0.5)
  )
```

## Las losowy

```{r cm_rfplot}
#| label: fig-cm_rf
#| fig-cap: Macierz konfuzji lasu losowego na imputowanym zbiorze danych
DataFrame_cm <- as.data.frame(cm_rf$table)
names(DataFrame_cm) <- c("Truth", "Prediction", "Częstotliwość")

# Visualization
ggplot(DataFrame_cm, aes(x = Truth, y = Prediction, fill = Częstotliwość)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Częstotliwość), vjust = 1.5, color = "white", size = 5) +
  scale_fill_gradient(low = "lightblue", high = "blue") +
  labs(
    title = "Macierz konfuzji", x = "Obserwowane",
    y = "Prawdziwe"
  ) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    plot.title = element_text(hjust = 0.5)
  )
```

## XGBoost

```{r cmboostplot}
#| label: fig-boost
#| fig-cap: Macierz konfuzji boostingu
DataFrame_cm <- as.data.frame(cm_boost$table)
names(DataFrame_cm) <- c("Truth", "Prediction", "Częstotliwość")

# Visualization
ggplot(DataFrame_cm, aes(x = Truth, y = Prediction, fill = Częstotliwość)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Częstotliwość), vjust = 1.5, color = "white", size = 5) +
  scale_fill_gradient(low = "lightblue", high = "blue") +
  labs(
    title = "Macierz konfuzji", x = "Obserwowane",
    y = "Prawdziwe"
  ) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    plot.title = element_text(hjust = 0.5)
  )
```

## SVM

```{r cmsvmplot}
#| label: fig-svm
#| fig-cap: Macierz konfuzji SVM
DataFrame_cm <- as.data.frame(cm_svm$table)
names(DataFrame_cm) <- c("Truth", "Prediction", "Częstotliwość")

# Visualization
ggplot(DataFrame_cm, aes(x = Truth, y = Prediction, fill = Częstotliwość)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Częstotliwość), vjust = 1.5, color = "white", size = 5) +
  scale_fill_gradient(low = "lightblue", high = "blue") +
  labs(
    title = "Macierz konfuzji", x = "Obserwowane",
    y = "Prawdziwe"
  ) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    plot.title = element_text(hjust = 0.5)
  )
```

## Bagging

```{r cmbagplot}
#| label: fig-bag
#| fig-cap: Macierz konfuzji Baggingu
DataFrame_cm <- as.data.frame(cm_bag$table)
names(DataFrame_cm) <- c("Truth", "Prediction", "Częstotliwość")

# Visualization
ggplot(DataFrame_cm, aes(x = Truth, y = Prediction, fill = Częstotliwość)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Częstotliwość), vjust = 1.5, color = "white", size = 5) +
  scale_fill_gradient(low = "lightblue", high = "blue") +
  labs(
    title = "Macierz konfuzji", x = "Obserwowane",
    y = "Prawdziwe"
  ) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    plot.title = element_text(hjust = 0.5)
  )
```

## RDA

```{r cmrdaplot}
#| label: fig-rda
#| fig-cap: Macierz konfuzji RDA
DataFrame_cm <- as.data.frame(cm_rda$table)
names(DataFrame_cm) <- c("Truth", "Prediction", "Częstotliwość")

# Visualization
ggplot(DataFrame_cm, aes(x = Truth, y = Prediction, fill = Częstotliwość)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Częstotliwość), vjust = 1.5, color = "white", size = 5) +
  scale_fill_gradient(low = "lightblue", high = "blue") +
  labs(
    title = "Macierz konfuzji", x = "Obserwowane",
    y = "Prawdziwe"
  ) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    plot.title = element_text(hjust = 0.5)
  )
```

:::

Na podstawie wszystkich wyników możemy stwierdzić, że najlepiej dopasował się model wektorów nośnych. Inne modele, poza pierwotnym, nie są daleko i również są to dobre wyniki.

Warto również zaznaczyć, że przez małą liczebność obserwacji, wyniki nie są stabilne - zmiana jądra generatora może je kompletnie zmienić.

# Źródła

-   [Zbiór danych](https://archive.ics.uci.edu/dataset/354/gps+trajectories)

### Wykorzystane biblioteki

-   `rio`
-   `doParallel`
-   `tidyverse`
-   `dplyr`
-   `gt`
-   `naniar`
-   `tidymodels`
-   `styler`
-   `themis`
-   `bestNormalize`